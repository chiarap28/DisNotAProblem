{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model1-HWR-byclass-upper-noDA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaamsQlM5zPi",
        "outputId": "9f231545-9c70-48cc-b17e-525c246442c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "pip install emnist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emnist\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/f4/78b24acbef9e8fe976dda700f16a3606f3b8363b015bc555f8050fbbd8ac/emnist-0.0-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from emnist) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from emnist) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from emnist) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->emnist) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->emnist) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->emnist) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->emnist) (3.0.4)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzz5cngH59he",
        "outputId": "9d70d41c-a884-4128-ff35-3c02ed362ae4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from emnist import list_datasets, extract_training_samples, extract_test_samples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-65f02b36625c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0memnist\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_datasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_training_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_test_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'emnist'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w6qPaD56HaU"
      },
      "source": [
        "# load emnist dataset 'by class'\n",
        "\n",
        "images, labels = extract_training_samples('byclass')\n",
        "images_test, labels_test = extract_test_samples('byclass')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgkMrn-N6WJP"
      },
      "source": [
        "# find index of uppercase letters\n",
        "\n",
        "tr_index_UPP = [i for i in range(len(labels)) if labels[i]>=10 and labels[i] <= 35] \n",
        "ts_index_UPP = [i for i in range(len(labels_test)) if labels_test[i]>=10 and labels_test[i] <= 35]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjpAgQBL6hxs"
      },
      "source": [
        "# save images and labels in uppercase\n",
        "\n",
        "im_train_UPP = images[tr_index_UPP]\n",
        "im_test_UPP = images_test[ts_index_UPP]\n",
        "lab_train_UPP = labels[tr_index_UPP]\n",
        "lab_test_UPP = labels_test[ts_index_UPP]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_99A-YR6uY3"
      },
      "source": [
        "# reformulate labels for application of built-in function 'to_categorical'\n",
        "\n",
        "alf_UPP = {\n",
        "       10: 0,\n",
        "       11: 1,\n",
        "       12: 2,\n",
        "       13: 3,\n",
        "       14: 4,\n",
        "       15: 5,\n",
        "       16: 6,\n",
        "       17: 7,\n",
        "       18: 8,\n",
        "       19: 9,\n",
        "       20: 10,\n",
        "       21: 11,\n",
        "       22: 12,\n",
        "       23: 13,\n",
        "       24: 14,\n",
        "       25: 15,\n",
        "       26: 16,\n",
        "       27: 17,\n",
        "       28: 18,\n",
        "       29: 19,\n",
        "       30: 20,\n",
        "       31: 21,\n",
        "       32: 22,\n",
        "       33: 23,\n",
        "       34: 24,\n",
        "       35: 25,\n",
        "       }\n",
        "\n",
        "lab_train_UPP = [alf_UPP[label] for label in lab_train_UPP]\n",
        "lab_test_UPP = [alf_UPP[label] for label in lab_test_UPP]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXvoJ4X1_595"
      },
      "source": [
        "# check labels\n",
        "\n",
        "lab_train_UPP[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj8i4Tyw_72J"
      },
      "source": [
        "# define image width and height and batch size\n",
        "\n",
        "# Batch size for training and validation\n",
        "batch_size = 32\n",
        "\n",
        "# Desired image dimensions\n",
        "img_width = 28\n",
        "img_height = 28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txkyxT3JDili"
      },
      "source": [
        "# split training set in traininig and validation set\n",
        "\n",
        "def split_data(images, labels, train_size=0.9, shuffle=True):\n",
        "    # 1. Get the total size of the dataset\n",
        "    size = len(images)\n",
        "    # 2. Make an indices array and shuffle it, if required\n",
        "    indices = np.arange(size)\n",
        "    if shuffle:\n",
        "        np.random.shuffle(indices)\n",
        "    # 3. Get the size of training samples\n",
        "    train_samples = int(size * train_size)\n",
        "    # 4. Split data into training and validation sets\n",
        "    x_train, y_train = images[indices[:train_samples]], labels[indices[:train_samples]]\n",
        "    x_valid, y_valid = images[indices[train_samples:]], labels[indices[train_samples:]]\n",
        "    return x_train, x_valid, y_train, y_valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Vp7uXl8Hamn"
      },
      "source": [
        "# Splitting data into training and validation sets\n",
        "x_train_UPP, x_valid_UPP, y_train_UPP, y_valid_UPP = split_data(np.array(im_train_UPP), np.array(lab_train_UPP))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlmupJ5eIGDF"
      },
      "source": [
        "# to categorical \n",
        "\n",
        "y_train_UPP = tf.keras.utils.to_categorical(y_train_UPP, 26)\n",
        "y_valid_UPP = tf.keras.utils.to_categorical(y_valid_UPP, 26)\n",
        "lab_test_UPP = tf.keras.utils.to_categorical(lab_test_UPP, 26)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvQPt1RXI-OV"
      },
      "source": [
        "# normalize training, validation and test data\n",
        "\n",
        "x_train_UPP = tf.keras.utils.normalize(x_train_UPP, axis=1)\n",
        "x_valid_UPP = tf.keras.utils.normalize(x_valid_UPP, axis=1)\n",
        "im_test_UPP = tf.keras.utils.normalize(im_test_UPP, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoml2gmkNnLr"
      },
      "source": [
        "# build model\n",
        "\n",
        "def build_model():\n",
        "    # Inputs to the model\n",
        "    input_img = layers.Input(\n",
        "        shape=(img_width, img_height, 1), name=\"image\", dtype=\"float32\"\n",
        "    )\n",
        "\n",
        "    # Output layer\n",
        "    x = layers.Dense(units=256, activation='sigmoid', name='dense_1')(input_img)\n",
        "    x = layers.Dense(units=128, activation=\"sigmoid\", name=\"dense2\")(x)\n",
        "    x = layers.Dense(units=64, activation=\"sigmoid\", name=\"dense3\")(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    output = layers.Dense(units=26, activation=\"softmax\", name=\"dense4\")(x)\n",
        "\n",
        "    # Define the model\n",
        "    model = keras.models.Model(\n",
        "        inputs=input_img, outputs=output, name=\"ocr_model_v1\"\n",
        "    )\n",
        "    # Optimizer\n",
        "    opt = keras.optimizers.Adam()\n",
        "    # Compile the model and return\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCVkysqePH29"
      },
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8YiuOWiPKKM"
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='/content/drive/My Drive/TESI/Models/Immagini/model5_byclass_upper_noDA.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bupp_Vi9PtBO"
      },
      "source": [
        "epochs = 100\n",
        "early_stopping_patience = 10\n",
        "# Add early stopping\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_accuracy\", patience=early_stopping_patience, restore_best_weights=True, verbose=1\n",
        ")\n",
        "\n",
        "# Model CheckPoint\n",
        "cp = keras.callbacks.ModelCheckpoint('/content/drive/My Drive/TESI/Models/model5_UPP_byclass_noDA.h5',\n",
        "                                     verbose=1,\n",
        "                                     monitor='val_accuracy',\n",
        "                                     save_best_only=True,\n",
        "                                     mode='max')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU2qe4yJQVK5"
      },
      "source": [
        "# fit model\n",
        "history1_UPP = model.fit(x_train_UPP,y_train_UPP,\n",
        "                    validation_data=(x_valid_UPP,y_valid_UPP),\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    callbacks=[cp, early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXHdIbq7Qv_I"
      },
      "source": [
        "plt.figure(figsize=(16,9))\n",
        "# summarize history for accuracy\n",
        "plt.plot(history1_UPP.history['accuracy'])\n",
        "plt.plot(history1_UPP.history['val_accuracy'])\n",
        "plt.title('Model 5 uppercase letters accuracy (without Data Augmentation)')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='lower right')\n",
        "plt.show()\n",
        "plt.figure(figsize=(16,9))\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history1_UPP.history['loss'])\n",
        "plt.plot(history1_UPP.history['val_loss'])\n",
        "plt.title('Model 5 uppercase letters loss (without Data Augmentation)')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOltsguOxFJp"
      },
      "source": [
        "evaluation = model.evaluate(im_test_UPP, lab_test_UPP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMRCeTWLyimv"
      },
      "source": [
        "evaluation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b6yNk-c-oqX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}